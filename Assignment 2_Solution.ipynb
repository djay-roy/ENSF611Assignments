{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92778525",
   "metadata": {},
   "source": [
    "# Assignment 2: Linear Models and Validation Metrics (30 marks total)\n",
    "### Due: October 10 at 11:59pm\n",
    "\n",
    "### Name: Dhananjay Roy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce31b39a",
   "metadata": {},
   "source": [
    "### In this assignment, you will need to write code that uses linear models to perform classification and regression tasks. You will also be asked to describe the process by which you came up with the code. More details can be found below. Please cite any websites or AI tools that you used to help you with this assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c6de86",
   "metadata": {},
   "source": [
    "## Part 1: Classification (14.5 marks total)\n",
    "\n",
    "You have been asked to develop code that can help the user determine if the email they have received is spam or not. Following the machine learning workflow described in class, write the relevant code in each of the steps below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3c6fc8",
   "metadata": {},
   "source": [
    "### Step 0: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33f86925",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9d33a8",
   "metadata": {},
   "source": [
    "### Step 1: Data Input (1 mark)\n",
    "\n",
    "The data used for this task can be downloaded using the yellowbrick library: \n",
    "https://www.scikit-yb.org/en/latest/api/datasets/spam.html\n",
    "\n",
    "Use the yellowbrick function `load_spam()` to load the spam dataset into the feature matrix `X` and target vector `y`.\n",
    "\n",
    "Print the size and type of `X` and `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33583c67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4600, 57)\n",
      "(4600,)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "\n",
      "word_freq_make                float64\n",
      "word_freq_address             float64\n",
      "word_freq_all                 float64\n",
      "word_freq_3d                  float64\n",
      "word_freq_our                 float64\n",
      "word_freq_over                float64\n",
      "word_freq_remove              float64\n",
      "word_freq_internet            float64\n",
      "word_freq_order               float64\n",
      "word_freq_mail                float64\n",
      "word_freq_receive             float64\n",
      "word_freq_will                float64\n",
      "word_freq_people              float64\n",
      "word_freq_report              float64\n",
      "word_freq_addresses           float64\n",
      "word_freq_free                float64\n",
      "word_freq_business            float64\n",
      "word_freq_email               float64\n",
      "word_freq_you                 float64\n",
      "word_freq_credit              float64\n",
      "word_freq_your                float64\n",
      "word_freq_font                float64\n",
      "word_freq_000                 float64\n",
      "word_freq_money               float64\n",
      "word_freq_hp                  float64\n",
      "word_freq_hpl                 float64\n",
      "word_freq_george              float64\n",
      "word_freq_650                 float64\n",
      "word_freq_lab                 float64\n",
      "word_freq_labs                float64\n",
      "word_freq_telnet              float64\n",
      "word_freq_857                 float64\n",
      "word_freq_data                float64\n",
      "word_freq_415                 float64\n",
      "word_freq_85                  float64\n",
      "word_freq_technology          float64\n",
      "word_freq_1999                float64\n",
      "word_freq_parts               float64\n",
      "word_freq_pm                  float64\n",
      "word_freq_direct              float64\n",
      "word_freq_cs                  float64\n",
      "word_freq_meeting             float64\n",
      "word_freq_original            float64\n",
      "word_freq_project             float64\n",
      "word_freq_re                  float64\n",
      "word_freq_edu                 float64\n",
      "word_freq_table               float64\n",
      "word_freq_conference          float64\n",
      "char_freq_;                   float64\n",
      "char_freq_(                   float64\n",
      "char_freq_[                   float64\n",
      "char_freq_!                   float64\n",
      "char_freq_$                   float64\n",
      "char_freq_#                   float64\n",
      "capital_run_length_average    float64\n",
      "capital_run_length_longest      int64\n",
      "capital_run_length_total        int64\n",
      "dtype: object\n",
      "int64\n"
     ]
    }
   ],
   "source": [
    "# TO DO: Import spam dataset from yellowbrick library\n",
    "\n",
    "from yellowbrick.datasets import load_spam\n",
    "import mglearn\n",
    "import yellowbrick\n",
    "\n",
    "X,y = load_spam()\n",
    "\n",
    "# TO DO: Print size and type of X and y\n",
    "\n",
    "# Print the shape of X and y\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "# Print the type of X and y\n",
    "print(type(X))\n",
    "print(type(y))\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "# Print the data types within X and y\n",
    "print(X.dtypes)\n",
    "print(y.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156db208",
   "metadata": {},
   "source": [
    "### Step 2: Data Processing (1.5 marks)\n",
    "\n",
    "Check to see if there are any missing values in the dataset. If necessary, select an appropriate method to fill-in the missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e7204f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in X: 0\n",
      "Missing values in y: 0\n"
     ]
    }
   ],
   "source": [
    "# TO DO: Check if there are any missing values and fill them in if necessary\n",
    "print(\"Missing values in X: \" + str(X.isnull().sum().sum()))\n",
    "\n",
    "print(\"Missing values in y: \" + str(y.isnull().sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a489285a",
   "metadata": {},
   "source": [
    "For this task, we want to test if the linear model would still work if we used less data. Use the `train_test_split` function from sklearn to create a new feature matrix named `X_small` and a new target vector named `y_small` that contain **5%** of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9bc4a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: Create X_small and y_small\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Train/Test split for the complete dataset\n",
    "X_train, X_val, y_train, y_val = train_test_split(X,y, stratify= y ,random_state=0)\n",
    "\n",
    "# Train/Test split for only the first two features\n",
    "X_train_f2, X_val_f2, y_train_f2, y_val_f2 = train_test_split(X.iloc[:, :2],y,random_state=0)\n",
    "\n",
    "# Creating a small dataset and then performing Train/Test split on it\n",
    "X_small,_,y_small,_ = train_test_split(X,y, train_size=0.05, random_state=0)\n",
    "X_small_train,X_small_val,y_small_train,y_small_val = train_test_split(X_small,y_small, random_state=0)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e6c46f",
   "metadata": {},
   "source": [
    "### Step 3: Implement Machine Learning Model\n",
    "\n",
    "1. Import `LogisticRegression` from sklearn\n",
    "2. Instantiate model `LogisticRegression(max_iter=2000)`.\n",
    "3. Implement the machine learning model with three different datasets: \n",
    "    - `X` and `y`\n",
    "    - Only first two columns of `X` and `y`\n",
    "    - `X_small` and `y_small`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d43a2969",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=2000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=2000)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=2000)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Instantiate the model\n",
    "fullDatasetModel = LogisticRegression(max_iter=2000)\n",
    "twoColumnsModel = LogisticRegression(max_iter=2000)\n",
    "smallDatasetModel = LogisticRegression(max_iter=2000)\n",
    "\n",
    "# Implement the model with the full dataset X and y\n",
    "fullDatasetModel.fit(X_train, y_train)\n",
    "\n",
    "# Implement the model with only the first two columns of X and y\n",
    "twoColumnsModel.fit(X_train_f2, y_train_f2)\n",
    "\n",
    "# Implement the model with the small dataset X_small and y_small\n",
    "smallDatasetModel.fit(X_small_train, y_small_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89f3d84",
   "metadata": {},
   "source": [
    "### Step 4: Validate Model\n",
    "\n",
    "Calculate the training and validation accuracy for the three different tests implemented in Step 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "519596e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score for X & y dataset: 0.9339\n",
      "Validation set score for X & y dataset: 0.9313\n",
      "\n",
      "Training set score for the first two column X & y dataset: 0.6084\n",
      "Validation set score for the first two columns X & y dataset: 0.6130\n",
      "\n",
      "Training set score for the X small and y small dataset: 0.9348\n",
      "Validation set score for the X small and y small dataset: 0.9310\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training set score for X & y dataset: {fullDatasetModel.score(X_train, y_train):.4f}\")\n",
    "print(f\"Validation set score for X & y dataset: {fullDatasetModel.score(X_val, y_val):.4f}\")\n",
    "print(\"\")\n",
    "print(f\"Training set score for the first two column X & y dataset: {twoColumnsModel.score(X_train_f2, y_train_f2):.4f}\")\n",
    "print(f\"Validation set score for the first two columns X & y dataset: {twoColumnsModel.score(X_val_f2, y_val_f2):.4f}\")\n",
    "print(\"\")\n",
    "print(f\"Training set score for the X small and y small dataset: {smallDatasetModel.score(X_small, y_small):.4f}\")\n",
    "print(f\"Validation set score for the X small and y small dataset: {smallDatasetModel.score(X_small_val, y_small_val):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352106a3",
   "metadata": {},
   "source": [
    "### Step 5: Visualize Results (4 marks)\n",
    "\n",
    "1. Create a pandas DataFrame `results` with columns: Data size, training accuracy, validation accuracy\n",
    "2. Add the data size, training and validation accuracy for each dataset to the `results` DataFrame\n",
    "3. Print `results`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be4b5c0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            Data size  Training Accuracy  Validation Accuracy\n",
      "0               Original Data: 262200           0.933913             0.931304\n",
      "1  First two columns of X and y: 9200           0.608406             0.613043\n",
      "2                   Small Data: 13110           0.934783             0.931034\n"
     ]
    }
   ],
   "source": [
    "# TODO: ADD YOUR CODE HERE FOR STEPS 3-5\n",
    "# Note: for any random state parameters, you can use random_state = 0\n",
    "# HINT: USING A LOOP TO STORE THE DATA IN YOUR RESULTS DATAFRAME WILL BE MORE EFFICIENT\n",
    "\n",
    "results = pd.DataFrame(columns=['Data size', 'Training Accuracy', 'Validation Accuracy'])\n",
    "results['Data size'] = ['Original Data: '+ str(X.size), 'First two columns of X and y: ' + str((X.iloc[:,0:2]).size), 'Small Data: '+ str(X_small.size)]\n",
    "\n",
    "results['Training Accuracy'] = [fullDatasetModel.score(X_train, y_train), twoColumnsModel.score(X_train_f2, y_train_f2), smallDatasetModel.score(X_small, y_small)]\n",
    "results['Validation Accuracy'] = [fullDatasetModel.score(X_val, y_val), twoColumnsModel.score(X_val_f2, y_val_f2), smallDatasetModel.score(X_small_val, y_small_val)]\n",
    "print(results)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4427d4f",
   "metadata": {},
   "source": [
    "### Questions (4 marks)\n",
    "1. How do the training and validation accuracy change depending on the amount of data used? Explain with values.\n",
    "2. In this case, what do a false positive and a false negative represent? Which one is worse?\n",
    "\n",
    "*YOUR ANSWERS HERE*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ac4ae2",
   "metadata": {},
   "source": [
    "### Questions (4 marks)\n",
    "1. How do the training and validation accuracy change depending on the amount of data used? Explain with values.\n",
    "2. In this case, what do a false positive and a false negative represent? Which one is worse?\n",
    "\n",
    "Answer 1:\n",
    "\n",
    "The accuracy of the model varies significantly depending on the volume and nature of the data used for training and validation. When the model is trained using the original data, it achieves a training accuracy of 0.933913 and a validation accuracy of 0.931304. This high level of accuracy can be attributed to the rich and diverse dataset, which provides the model with ample opportunities to learn and generalize the underlying patterns effectively.\n",
    "\n",
    "Contrarily, when the dataset is stripped down to just the first two columns of X and y, containing 9200 samples, there is a noticeable drop in performance. The training accuracy plummets to 0.608406 and the validation accuracy to 0.613043. This decline underscores the model's struggle to learn and make accurate predictions due to the loss of crucial features and information.\n",
    "\n",
    "Interestingly, when trained on a small dataset, a subset containing 5% (13110 samples) of the original data but retaining all features, the model’s performance mirrors that of the original dataset, with a training accuracy of 0.934783 and a validation accuracy of 0.931034. This highlights the importance of feature diversity over volume, suggesting that a well-selected subset can be almost as effective as the complete dataset for training the model.\n",
    "\n",
    "Answer 2:\n",
    "\n",
    "In the context of email filtering, a false positive occurs when a legitimate email is incorrectly classified as spam, leading to its unwarranted relocation to the spam folder. A false negative, conversely, is when a spam email is misclassified as legitimate, causing it to appear in the user’s inbox.\n",
    "\n",
    "The severity of these errors can be subjective. However, often, false negatives are deemed more problematic. While a false positive could result in a user missing an important email, a false negative exposes the user to potential security risks, phishing scams, and unsolicited content, undermining the core purpose of spam filters - to enhance user security and experience by sieving out potentially harmful and undesired content.\n",
    "\n",
    "In summary, the model’s accuracy fluctuates with the volume and diversity of data. While a full, diverse dataset yields optimal performance, a well-chosen subset can deliver comparable results. Feature loss, however, as demonstrated by the model trained only on the first two columns of X and y, can lead to significant performance degradation. In the realm of spam filtering, false negatives pose a greater risk, potentially compromising user security and experience.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7559517a",
   "metadata": {},
   "source": [
    "### Process Description (4 marks)\n",
    "Please describe the process you used to create your code. Cite any websites or generative AI tools used. You can use the following questions as guidance:\n",
    "1. Where did you source your code?\n",
    "1. In what order did you complete the steps?\n",
    "1. If you used generative AI, what prompts did you use? Did you need to modify the code at all? Why or why not?\n",
    "1. Did you have any challenges? If yes, what were they? If not, what helped you to be successful?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59fe687f",
   "metadata": {},
   "source": [
    "1. Where did you source your code?\n",
    "\n",
    "My code was sourced from a combination of the lecture slides, practical examples in the Jupyter notebooks available on D2L, and interactive assistance from ChatGPT. Each source contributed to the overall development and refinement of my code.\n",
    "\n",
    "2. In what order did you complete the steps?\n",
    "\n",
    "I began by reviewing the lecture slides to establish a solid theoretical foundation on linear regression.\n",
    "Subsequently, I delved into the Jupyter notebooks on D2L to witness the practical application and gather insights to reinforce my understanding.\n",
    "To further clarify complex concepts and enhance my understanding, I turned to ChatGPT, which provided detailed explanations and guidance.\n",
    "\n",
    "3. If you used generative AI, what prompts did you use? Did you need to modify the code at all? Why or why not?\n",
    "\n",
    "I used ChatGPT to get deeper insights into concepts like mean squared error, R2 score, and model fit. The prompts were focused on explanations and Python implementations of these concepts.\n",
    "Minor modifications were made to the generated code to tailor it to the specific requirements and dataset of the assignment, ensuring relevance and accuracy.\n",
    "\n",
    "4. Did you have any challenges? If yes, what were they? If not, what helped you to be successful?\n",
    "\n",
    "Yes, I encountered challenges, particularly in understanding the specific Python commands and their outputs, like r2_score.\n",
    "ChatGPT played a crucial role in overcoming these challenges. The detailed explanations provided by the AI tool aided in demystifying the complex terms and concepts, granting me a clearer and more comprehensive understanding.\n",
    "\n",
    "Citations:\n",
    "\n",
    "OpenAI. (2023). ChatGPT API. Retrieved from https://www.openai.com/chatgpt-api\n",
    "\n",
    "Dawson, Leanne. (2023). ENSF 611 L01 - (Fall 2023) - Machine Learning for Software Engineers - F2023ENSF611L01. \n",
    "\n",
    "In Desire2Learn (Brightspace). https://d2l.ucalgary.ca/d2l/home/543310\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4c78a8",
   "metadata": {},
   "source": [
    "## Part 2: Regression (10.5 marks total)\n",
    "\n",
    "For this section, we will be evaluating concrete compressive strength of different concrete samples, based on age and ingredients. You will need to repeat the steps 1-4 from Part 1 for this analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ba83c5",
   "metadata": {},
   "source": [
    "### Step 1: Data Input (1 mark)\n",
    "\n",
    "The data used for this task can be downloaded using the yellowbrick library: \n",
    "https://www.scikit-yb.org/en/latest/api/datasets/concrete.html\n",
    "\n",
    "Use the yellowbrick function `load_concrete()` to load the spam dataset into the feature matrix `X` and target vector `y`.\n",
    "\n",
    "Print the size and type of `X` and `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ff2e34f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of X: (1030, 8)\n",
      "Size of y: (1030,)\n",
      "Type of X: <class 'pandas.core.frame.DataFrame'>\n",
      "Type of y: <class 'pandas.core.series.Series'>\n",
      "\n",
      "cement    float64\n",
      "slag      float64\n",
      "ash       float64\n",
      "water     float64\n",
      "splast    float64\n",
      "coarse    float64\n",
      "fine      float64\n",
      "age         int64\n",
      "dtype: object\n",
      "float64\n"
     ]
    }
   ],
   "source": [
    "# TO DO: Import spam dataset from yellowbrick library\n",
    "# TO DO: Print size and type of X and y\n",
    "\n",
    "from yellowbrick.datasets import load_concrete\n",
    "\n",
    "# Loading the concrete dataset\n",
    "X, y = load_concrete()\n",
    "\n",
    "# Print the size and type of X and y\n",
    "\n",
    "# Size of X and y\n",
    "print(\"Size of X:\", X.shape)\n",
    "print(\"Size of y:\", y.shape)\n",
    "\n",
    "# Type of X and y\n",
    "print(\"Type of X:\", type(X))\n",
    "print(\"Type of y:\", type(y))\n",
    "\n",
    "print(\"\")\n",
    "print(X.dtypes)\n",
    "print(y.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5294cfa",
   "metadata": {},
   "source": [
    "### Step 2: Data Processing (0.5 marks)\n",
    "\n",
    "Check to see if there are any missing values in the dataset. If necessary, select an appropriate method to fill-in the missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "693c5fa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in X: \n",
      "cement    0\n",
      "slag      0\n",
      "ash       0\n",
      "water     0\n",
      "splast    0\n",
      "coarse    0\n",
      "fine      0\n",
      "age       0\n",
      "dtype: int64\n",
      "Missing values in y: \n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# TO DO: Check if there are any missing values and fill them in if necessary\n",
    "# Checking for missing values in the dataset\n",
    "print(\"Missing values in X: \")\n",
    "print(X.isnull().sum())\n",
    "\n",
    "print(\"Missing values in y: \")\n",
    "print(y.isnull().sum())\n",
    "\n",
    "# Filling in missing values, if necessary\n",
    "# For simplicity, we'll use mean imputation for X and the mode for y\n",
    "\n",
    "if X.isnull().values.any():\n",
    "    X.fillna(X.mean(), inplace=True)\n",
    "    print(\"Missing values in X have been filled with the mean value of each column.\")\n",
    "\n",
    "if y.isnull().values.any():\n",
    "    y.fillna(y.mode()[0], inplace=True)\n",
    "    print(\"Missing values in y have been filled with the mode.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc60489",
   "metadata": {},
   "source": [
    "### Step 3: Implement Machine Learning Model (1 mark)\n",
    "\n",
    "1. Import `LinearRegression` from sklearn\n",
    "2. Instantiate model `LinearRegression()`.\n",
    "3. Implement the machine learning model with `X` and `y`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b5041945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [ 0.12185954  0.11060501  0.0953879  -0.1419938   0.31529263  0.02485841\n",
      "  0.02486899  0.11270849]\n",
      "Intercept: -36.54109819991135\n"
     ]
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "# Note: for any random state parameters, you can use random_state = 0\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Splitting the dataset into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, random_state=0)\n",
    "\n",
    "# Instantiating and fitting the Linear Regression model\n",
    "lr = LinearRegression().fit(X_train, y_train)\n",
    "\n",
    "# You can print out the coefficients and intercept to understand the fitted model\n",
    "print(\"Coefficients:\", lr.coef_)\n",
    "print(\"Intercept:\", lr.intercept_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de28482",
   "metadata": {},
   "source": [
    "### Step 4: Validate Model (1 mark)\n",
    "\n",
    "Calculate the training and validation accuracy using mean squared error and R2 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "970c038b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Training score: 111.36\n",
      "Mean Squared Validation score: 95.90\n",
      "\n",
      "R2 Training score: 0.611\n",
      "R2 Valdiation score: 0.623\n"
     ]
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "# Note: for any random state parameters, you can use random_state = 0\n",
    "\n",
    "print(\"Mean Squared Training score: {:.2f}\".format(mean_squared_error(y_train, lr.predict(X_train))))\n",
    "print(\"Mean Squared Validation score: {:.2f}\".format(mean_squared_error(y_val, lr.predict(X_val))))\n",
    "print('')\n",
    "print(\"R2 Training score: {:.3f}\".format(r2_score(y_train, lr.predict(X_train))))\n",
    "print(\"R2 Valdiation score: {:.3f}\".format(r2_score(y_val, lr.predict(X_val))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54aa7795",
   "metadata": {},
   "source": [
    "### Step 5: Visualize Results (1 mark)\n",
    "1. Create a pandas DataFrame `results` with columns: Training accuracy and Validation accuracy, and index: MSE and R2 score\n",
    "2. Add the accuracy results to the `results` DataFrame\n",
    "3. Print `results`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "88d223f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training Accuracy</th>\n",
       "      <th>Validation Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>111.36</td>\n",
       "      <td>95.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R2 Score</th>\n",
       "      <td>0.61</td>\n",
       "      <td>0.62</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Training Accuracy  Validation Accuracy\n",
       "MSE                  111.36                95.90\n",
       "R2 Score               0.61                 0.62"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "\n",
    "# Create results DataFrame\n",
    "results = pd.DataFrame(columns=['Training Accuracy', 'Validation Accuracy'], \n",
    "                       index=['MSE', 'R2 Score'])\n",
    "\n",
    "# Populate the DataFrame\n",
    "results['Training Accuracy'] = [\n",
    "    round(mean_squared_error(y_train, lr.predict(X_train)), 2),\n",
    "    round(r2_score(y_train, lr.predict(X_train)), 2)\n",
    "]\n",
    "\n",
    "results['Validation Accuracy'] = [\n",
    "    round(mean_squared_error(y_val, lr.predict(X_val)), 2),\n",
    "    round(r2_score(y_val, lr.predict(X_val)), 2)\n",
    "]\n",
    "\n",
    "# Print the results DataFrame\n",
    "results\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a42bda",
   "metadata": {},
   "source": [
    "### Questions (2 marks)\n",
    "1. Did using a linear model produce good results for this dataset? Why or why not?\n",
    "\n",
    "Assessment of Linear Model Performance:\n",
    "1. Evaluation Metrics:\n",
    "\n",
    "Within the linear model, we observed a Mean Squared Error (MSE) training score of 111.36 and a validation score of 95.90. For the R2 Score, the training and validation scores were 0.61 and 0.62 respectively.\n",
    "\n",
    "2. Analyzing the MSE:\n",
    "\n",
    "The relatively high MSE for both training and validation indicates the presence of significant variance that the linear model has failed to adequately capture, leading to potential prediction errors.\n",
    "\n",
    "3. R2 Score Insight:\n",
    "\n",
    "Given that an R2 score closer to 1 typically signifies a better model fit, the obtained R2 scores of approximately 0.6 suggest that the model is only able to explain around 60% of the variance in the data, which is not optimal.\n",
    "\n",
    "4. Conclusion:\n",
    "\n",
    "In light of the above metrics, it is evident that the linear model did not yield impressive results for this dataset. The elevated MSE and suboptimal R2 scores underscore a model that could be improved for enhanced prediction accuracy and explanatory power.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca0ff2f",
   "metadata": {},
   "source": [
    "### Process Description (4 marks)\n",
    "Please describe the process you used to create your code. Cite any websites or generative AI tools used. You can use the following questions as guidance:\n",
    "1. Where did you source your code?\n",
    "1. In what order did you complete the steps?\n",
    "1. If you used generative AI, what prompts did you use? Did you need to modify the code at all? Why or why not?\n",
    "1. Did you have any challenges? If yes, what were they? If not, what helped you to be successful?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfdb0880",
   "metadata": {},
   "source": [
    "Process and Approach:\n",
    "\n",
    "Review and Research:\n",
    "I initiated this section by thoroughly reviewing the lecture slides to grasp the theoretical foundations of linear regression.\n",
    "\n",
    "Practical Insights:\n",
    "The Jupyter notebooks available on D2L served as practical examples that supplemented my theoretical understanding.\n",
    "\n",
    "Assistance from ChatGPT:\n",
    "I sought further clarification and guidance from ChatGPT, particularly on complex concepts like mean squared error, R2 score, and model fit.\n",
    "\n",
    "Overcoming Challenges:\n",
    "\n",
    "Conceptual Clarity:\n",
    "ChatGPT was instrumental in demystifying complex terms and concepts, making the Python implementation process more comprehensible.\n",
    "\n",
    "Understanding Python Commands:\n",
    "I initially faced challenges in deciphering the functionality and outputs of certain Python commands, such as r2_score.\n",
    "\n",
    "Enhanced Understanding:\n",
    "With ChatGPT's assistance, I gained a clearer perspective on the command's application and interpretation, overcoming initial hurdles.\n",
    "\n",
    "\n",
    "Citations:\n",
    "Reference to ChatGPT:\n",
    "OpenAI. (2023). ChatGPT API. Retrieved from https://www.openai.com/chatgpt-api\n",
    "\n",
    "Course Material Reference:\n",
    "Dawson, Leanne. (2023). ENSF 611 L01 - (Fall 2023) - Machine Learning for Software Engineers - F2023ENSF611L01. In Desire2Learn (Brightspace). https://d2l.ucalgary.ca/d2l/home/543310\n",
    "\n",
    "Conclusion:\n",
    "\n",
    "Holistic Learning Experience:\n",
    "The combination of theoretical learning, practical examples, and interactive assistance from ChatGPT facilitated a comprehensive learning experience, enabling me to effectively navigate and complete this section of the assignment.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72ac3eb",
   "metadata": {},
   "source": [
    "## Part 3: Observations/Interpretation (3 marks)\n",
    "\n",
    "Describe any pattern you see in the results. Relate your findings to what we discussed during lectures. Include data to justify your findings.\n",
    "\n",
    "\n",
    "Part 1 - Impact of Dataset Size and Features:\n",
    "Limited Features and Dataset Size:\n",
    "\n",
    "Utilizing only the first two columns for the model led to significantly lower training (0.6084) and validation (0.6130) scores, indicating underperformance and potential underfitting.\n",
    "\n",
    "Full Dataset Performance:\n",
    "\n",
    "With the full dataset, the model achieved an impressive training score of 0.9339 and a validation score of 0.9313, exemplifying the enhanced accuracy attained with a comprehensive set of features and data.\n",
    "\n",
    "Small Dataset Limitations:\n",
    "\n",
    "The restricted small dataset, though well-trained, presented a training score of 0.9348 and a validation score of 0.9310. These scores, though high, underscore the nuanced role of dataset volume in predictive accuracy.\n",
    "\n",
    "Part 2 - Model Overfitting and Underfitting:\n",
    "Overfitting Evidence:\n",
    "\n",
    "The scenario of overfitting was not evidently present in this case, as the training and validation scores were quite consistent. However, it is always essential to monitor for high variance and inflated MSE scores.\n",
    "\n",
    "Underfitting in Specific Data Models:\n",
    "\n",
    "When only the first two columns of the dataset were utilized, both the training (0.6084) and validation (0.6130) R2 scores were markedly low, indicating a model that is too simplistic and potentially underfitted.\n",
    "\n",
    "Analysis and Insights:\n",
    "Feature Reduction Impact:\n",
    "\n",
    "The substantial reduction in scores when limiting the number of features highlights the essential role of feature selection and richness in achieving optimal model accuracy.\n",
    "\n",
    "Full Dataset Advantage:\n",
    "\n",
    "The comprehensive dataset, encompassing a wider array of features, demonstrated superior training and validation scores. This underscores the paramount importance of data volume and feature diversity in enhancing model performance.\n",
    "\n",
    "Model Simplicity Issue:\n",
    "\n",
    "The low scores associated with the model trained on the first two columns accentuate the pitfalls of an overly simplistic model. This scenario underscores the necessity for a balanced model complexity to navigate between underfitting and overfitting effectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b84eed",
   "metadata": {},
   "source": [
    "## Part 4: Reflection (2 marks)\n",
    "Include a sentence or two about:\n",
    "- what you liked or disliked,\n",
    "- found interesting, confusing, challangeing, motivating\n",
    "while working on this assignment.\n",
    "\n",
    "Enjoyment and Excitement:\n",
    "\n",
    "Python Commands:\n",
    "Enjoyed using Python to develop the first machine learning models, finding it an exciting hands-on experience.\n",
    "\n",
    "Practical Application:\n",
    "Appreciated the opportunity to apply learned theories practically, enhancing comprehension of concepts.\n",
    "\n",
    "Learning and Insights:\n",
    "\n",
    "Understanding Models:\n",
    "Gained insights into linear and logistic models, fostering a rich learning environment.\n",
    "\n",
    "Training and Validation:\n",
    "The assignment provided a clearer understanding of the roles and dynamics of training and validation datasets.\n",
    "\n",
    "Model Evaluation:\n",
    "\n",
    "Found the process of assessing the model’s performance against data both interesting and challenging.\n",
    "\n",
    "Challenges and Confusion:\n",
    "\n",
    "Initial Confusion:\n",
    "Experienced confusion on performing train splits on three different datasets for Question 1.\n",
    "\n",
    "Overcoming Challenges:\n",
    "Clarity was gained as the assignment progressed, turning initial confusion into a significant learning moment.\n",
    "\n",
    "Overall Experience:\n",
    "\n",
    "Dynamic Learning:\n",
    "The assignment highlighted the dynamic nature of machine learning, with challenges leading to deeper understanding and skill enhancement.\n",
    "\n",
    "Enriching Experience:\n",
    "It was an enriching journey, blending technical exercises with substantial learning experiences, turning every challenge into an opportunity for growth and understanding\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db951b3a",
   "metadata": {},
   "source": [
    "## Part 5: Bonus Question (4 marks)\n",
    "\n",
    "Repeat Part 2 with Ridge and Lasso regression to see if you can improve the accuracy results. Which method and what value of alpha gave you the best R^2 score? Is this score \"good enough\"? Explain why or why not.\n",
    "\n",
    "**Remember**: Only test values of alpha from 0.001 to 100 along the logorithmic scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "47623d44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha: 0.001\n",
      "Ridge - Training score: 0.611, Validation score: 0.623\n",
      "Lasso - Training score: 0.611, Validation score: 0.623\n",
      "\n",
      "Alpha: 0.01\n",
      "Ridge - Training score: 0.611, Validation score: 0.623\n",
      "Lasso - Training score: 0.611, Validation score: 0.623\n",
      "\n",
      "Alpha: 0.1\n",
      "Ridge - Training score: 0.611, Validation score: 0.623\n",
      "Lasso - Training score: 0.611, Validation score: 0.624\n",
      "\n",
      "Alpha: 1.0\n",
      "Ridge - Training score: 0.611, Validation score: 0.623\n",
      "Lasso - Training score: 0.611, Validation score: 0.625\n",
      "\n",
      "Alpha: 10.0\n",
      "Ridge - Training score: 0.611, Validation score: 0.623\n",
      "Lasso - Training score: 0.604, Validation score: 0.627\n",
      "\n",
      "Alpha: 100.0\n",
      "Ridge - Training score: 0.611, Validation score: 0.623\n",
      "Lasso - Training score: 0.468, Validation score: 0.507\n",
      "\n",
      "Best Model: Lasso, Best Alpha: 10.0, Best R^2 Score: 0.627\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Function to train and get scores of the model\n",
    "def get_scores(model, X_train, y_train, X_val, y_val):\n",
    "    model.fit(X_train, y_train)\n",
    "    return model.score(X_train, y_train), model.score(X_val, y_val)\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, random_state=0)\n",
    "\n",
    "# Test alpha values along the logarithmic scale\n",
    "alphas = np.logspace(-3, 2, 6)  # Generates alpha values from 0.001 to 100\n",
    "\n",
    "best_score = 0\n",
    "best_alpha = 0\n",
    "best_model = None\n",
    "\n",
    "for alpha in alphas:\n",
    "    print(f\"Alpha: {alpha}\")\n",
    "    \n",
    "    # Ridge model\n",
    "    ridge = Ridge(alpha=alpha)\n",
    "    ridge_train_score, ridge_val_score = get_scores(ridge, X_train, y_train, X_val, y_val)\n",
    "    print(f\"Ridge - Training score: {ridge_train_score:.3f}, Validation score: {ridge_val_score:.3f}\")\n",
    "\n",
    "    # Update best score, alpha, and model\n",
    "    if ridge_val_score > best_score:\n",
    "        best_score = ridge_val_score\n",
    "        best_alpha = alpha\n",
    "        best_model = 'Ridge'\n",
    "    \n",
    "    # Lasso model\n",
    "    lasso = Lasso(alpha=alpha)\n",
    "    lasso_train_score, lasso_val_score = get_scores(lasso, X_train, y_train, X_val, y_val)\n",
    "    print(f\"Lasso - Training score: {lasso_train_score:.3f}, Validation score: {lasso_val_score:.3f}\")\n",
    "    print(\"\")\n",
    "\n",
    "    # Update best score, alpha, and model\n",
    "    if lasso_val_score > best_score:\n",
    "        best_score = lasso_val_score\n",
    "        best_alpha = alpha\n",
    "        best_model = 'Lasso'\n",
    "\n",
    "print(f\"Best Model: {best_model}, Best Alpha: {best_alpha}, Best R^2 Score: {best_score:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b606236",
   "metadata": {},
   "source": [
    "*ANSWER HERE*\n",
    "\n",
    "1. Model Training with Various Alphas:\n",
    "Ridge and Lasso Regression: Both models are trained using a range of alpha values to identify the optimal alpha for best performance.\n",
    "Alpha Range: Alphas are tested along a logarithmic scale from 0.001 to 100 to capture the diverse effects of regularization strength.\n",
    "2. Evaluation Metrics:\n",
    "R^2 Score: The primary metric for evaluation, indicating the proportion of the variance in the dependent variable that is predictable from the independent variable(s).\n",
    "Training and Validation Scores: Both scores are calculated for a comprehensive evaluation and to check for overfitting or underfitting.\n",
    "3. Parameter Tuning:\n",
    "Alpha Tuning: The alpha parameter in Ridge and Lasso regression is tuned to optimize the model's performance.\n",
    "Logarithmic Scale: Alphas are selected along this scale to ensure a wide and appropriate range of values is tested.\n",
    "4. Results and Comparison:\n",
    "Best Model and Alpha: The model (Ridge or Lasso) and alpha that give the highest R^2 score on the validation set are identified.\n",
    "Performance Metrics: The corresponding R^2 scores offer insights into the model's predictive accuracy and goodness of fit.\n",
    "5. Assessment of the \"Goodness\" of Score:\n",
    "R^2 Score Close to 1: Indicates that a significant proportion of the variance in the output variable has been captured by the model.\n",
    "Overfitting Concern: A high R^2 score isn't conclusive evidence of a good model; overfitting needs to be checked, especially when the training score is significantly higher than the validation score.\n",
    "Model Complexity and Interpretability: A balance is required to ensure the model is not too complex (leading to overfitting) or too simple (leading to underfitting) and remains interpretable.\n",
    "6. Practical Implications:\n",
    "Context-Dependent: The acceptability of the R^2 score is contingent upon the specific application, domain, and objectives.\n",
    "Complementary Evaluation: Other metrics and qualitative assessments should accompany the R^2 score to offer a holistic view of model performance.\n",
    "Model Validation: Further validation techniques, like cross-validation, can offer more robust insights into the model’s predictive performance.\n",
    "7. Future Steps:\n",
    "Feature Engineering: Enhancements in this area can lead to improved model performance.\n",
    "Model Selection: Exploring other regression models or machine learning algorithms may yield better results.\n",
    "Hyperparameter Tuning: More exhaustive techniques like grid search or random search can be employed for more refined tuning of alpha and other hyperparameters."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
